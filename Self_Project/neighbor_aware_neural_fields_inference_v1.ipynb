{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12667203,"sourceType":"datasetVersion","datasetId":8004849},{"sourceId":507680,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":402875,"modelId":420813},{"sourceId":507705,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":402895,"modelId":420831},{"sourceId":507906,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":403071,"modelId":421007}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install vtk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:28:59.723709Z","iopub.execute_input":"2025-08-05T12:28:59.724031Z","iopub.status.idle":"2025-08-05T12:29:02.716497Z","shell.execute_reply.started":"2025-08-05T12:28:59.724008Z","shell.execute_reply":"2025-08-05T12:29:02.715769Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: vtk in /usr/local/lib/python3.11/dist-packages (9.3.1)\nRequirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from vtk) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->vtk) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=2.0.0->vtk) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=2.0.0->vtk) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=2.0.0->vtk) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=2.0.0->vtk) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=2.0.0->vtk) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib>=2.0.0->vtk) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib>=2.0.0->vtk) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib>=2.0.0->vtk) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib>=2.0.0->vtk) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib>=2.0.0->vtk) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib>=2.0.0->vtk) (2024.2.0)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport vtk\nfrom vtkmodules.util import numpy_support\n\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.optim import lr_scheduler\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:29:02.718271Z","iopub.execute_input":"2025-08-05T12:29:02.718520Z","iopub.status.idle":"2025-08-05T12:29:02.723051Z","shell.execute_reply.started":"2025-08-05T12:29:02.718484Z","shell.execute_reply":"2025-08-05T12:29:02.722487Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class SineLayer(nn.Module):\n    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30):\n        super().__init__()\n        self.omega_0 = omega_0\n        self.is_first = is_first\n        self.in_features = in_features\n        self.linear = nn.Linear(in_features, out_features, bias=bias)\n        self.init_weights()\n    def init_weights(self):\n        with torch.no_grad():\n            if self.is_first:\n                self.linear.weight.uniform_(-1 / self.in_features, 1 / self.in_features)\n            else:\n                self.linear.weight.uniform_(\n                    -np.sqrt(6 / self.in_features) / self.omega_0,\n                    np.sqrt(6 / self.in_features) / self.omega_0\n                )\n    def forward(self, x):\n        return torch.sin(self.omega_0 * self.linear(x))\n\nclass ResidualSineLayer(nn.Module):\n    def __init__(self, features, bias=True, ave_first=False, ave_second=False, omega_0=30):\n        super().__init__()\n        self.omega_0 = omega_0\n        self.features = features\n        self.linear_1 = nn.Linear(features, features, bias=bias)\n        self.linear_2 = nn.Linear(features, features, bias=bias)\n        self.weight_1 = 0.5 if ave_first else 1\n        self.weight_2 = 0.5 if ave_second else 1\n        self.init_weights()\n    def init_weights(self):\n        with torch.no_grad():\n            self.linear_1.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n                                         np.sqrt(6 / self.features) / self.omega_0)\n            self.linear_2.weight.uniform_(-np.sqrt(6 / self.features) / self.omega_0,\n                                         np.sqrt(6 / self.features) / self.omega_0)\n    def forward(self, input):\n        sine_1 = torch.sin(self.omega_0 * self.linear_1(self.weight_1 * input))\n        sine_2 = torch.sin(self.omega_0 * self.linear_2(sine_1))\n        return self.weight_2 * (input + sine_2)\n\nclass MyResidualSirenNet(nn.Module):\n    def __init__(self, num_layers, neurons_per_layer, num_input_dim, num_output_dim):\n        super().__init__()\n        self.Omega_0 = 30\n        self.n_layers = num_layers + 1\n        self.input_dim = num_input_dim\n        self.output_dim = num_output_dim\n        self.neurons_per_layer = neurons_per_layer\n        self.layers = [self.input_dim] + [self.neurons_per_layer] * num_layers + [self.output_dim]\n        self.net_layers = nn.ModuleList()\n        for idx in range(self.n_layers):\n            layer_in = self.layers[idx]\n            layer_out = self.layers[idx + 1]\n            if idx != self.n_layers - 1:\n                if idx == 0:\n                    self.net_layers.append(SineLayer(layer_in, layer_out, bias=True, is_first=True))\n                else:\n                    self.net_layers.append(ResidualSineLayer(layer_in, bias=True,\n                                                             ave_first=idx > 1,\n                                                             ave_second=idx == (self.n_layers - 2)))\n            else:\n                final_linear = nn.Linear(layer_in, layer_out)\n                with torch.no_grad():\n                    final_linear.weight.uniform_(-np.sqrt(6 / layer_in) / self.Omega_0,\n                                                np.sqrt(6 / layer_in) / self.Omega_0)\n                self.net_layers.append(final_linear)\n    def forward(self, x):\n        for net_layer in self.net_layers:\n            x = net_layer(x)\n        return x\n\n# === ADD: For generalizing to 20-neighbor output configuration, specify neighbor offsets next cell\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:29:02.723877Z","iopub.execute_input":"2025-08-05T12:29:02.724132Z","iopub.status.idle":"2025-08-05T12:29:02.741931Z","shell.execute_reply.started":"2025-08-05T12:29:02.724111Z","shell.execute_reply":"2025-08-05T12:29:02.741263Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def read_vti_file(input_data_file):\n    reader = vtk.vtkXMLImageDataReader()\n    reader.SetFileName(input_data_file)\n    reader.Update()\n    return reader.GetOutput()\n\ndef data_setup(vti_data, varname):\n    dims = vti_data.GetDimensions()\n    spacing = vti_data.GetSpacing()\n    origin = vti_data.GetOrigin()\n    coords = np.array([[x, y, z]\n                       for z in range(dims[2])\n                       for y in range(dims[1])\n                       for x in range(dims[0])], dtype=np.float32)\n    arr = numpy_support.vtk_to_numpy(vti_data.GetPointData().GetArray(varname)).reshape(-1, 1)\n    return coords, arr, dims\n\n# 18 offsets: 6 faces + 12 edges\nNEIGHBOR_OFFSETS = [\n    (1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1),      # Faces\n    (1,1,0), (1,-1,0), (-1,1,0), (-1,-1,0),\n    (1,0,1), (1,0,-1), (-1,0,1), (-1,0,-1),\n    (0,1,1), (0,1,-1), (0,-1,1), (0,-1,-1)                        # Edges\n]\n\ndef get_N_neighbors(coord, dims, offsets=NEIGHBOR_OFFSETS):\n    x, y, z = [int(xx) for xx in coord]\n    neighbors = []\n    for dx, dy, dz in offsets:\n        nx, ny, nz = x+dx, y+dy, z+dz\n        if 0 <= nx < dims[0] and 0 <= ny < dims[1] and 0 <= nz < dims[2]:\n            neighbors.append([nx, ny, nz])\n        else:\n            neighbors.append(None)\n    return neighbors\n\ndef compute_PSNR(pred, gt, data_min, data_max):\n    mse = np.mean((pred - gt) ** 2)\n    if mse == 0:\n        return float('inf')\n    pixel_range = data_max - data_min\n    return 20 * np.log10(pixel_range / np.sqrt(mse))\n\ndef compute_rmse(pred, gt):\n    return np.sqrt(np.mean((pred - gt) ** 2))\n\ndef normalize_data(data):\n    data_min = np.min(data)\n    data_max = np.max(data)\n    data_norm = 2 * (data - data_min) / (data_max - data_min + 1e-8) - 1\n    return data_norm, data_min, data_max\n\ndef denormalize_data(data_norm, data_min, data_max):\n    return 0.5 * (data_norm + 1) * (data_max - data_min + 1e-8) + data_min\n\n# (You can also add plot_histograms etc. as needed.)\ndef save_combined_volume(vti_data, pressure_data, uncertainty_data, outpath, dataset_name, postfix=\"combined_20out\"):\n    import vtk\n    pressure_array = vtk.vtkFloatArray()\n    pressure_array.SetName(\"Pressure_Reconstructed\")\n    pressure_array.SetNumberOfComponents(1)\n    pressure_array.SetNumberOfTuples(len(pressure_data))\n    for i in range(len(pressure_data)):\n        pressure_array.SetTuple1(i, float(pressure_data[i]))\n\n    uncertainty_array = vtk.vtkFloatArray()\n    uncertainty_array.SetName(\"Uncertainty\")\n    uncertainty_array.SetNumberOfComponents(1)\n    uncertainty_array.SetNumberOfTuples(len(uncertainty_data))\n    for i in range(len(uncertainty_data)):\n        uncertainty_array.SetTuple1(i, float(uncertainty_data[i]))\n\n    vti_data.GetPointData().SetScalars(pressure_array)\n    vti_data.GetPointData().AddArray(uncertainty_array)\n\n    writer = vtk.vtkXMLImageDataWriter()\n    output_file = f\"{outpath}/{dataset_name}_{postfix}.vti\"\n    writer.SetFileName(output_file)\n    writer.SetInputData(vti_data)\n    writer.Write()\n    print(\"Saved combined volume to:\", output_file)\n    return output_file\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:29:02.743445Z","iopub.execute_input":"2025-08-05T12:29:02.743647Z","iopub.status.idle":"2025-08-05T12:29:02.767408Z","shell.execute_reply.started":"2025-08-05T12:29:02.743633Z","shell.execute_reply":"2025-08-05T12:29:02.766805Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Parameters and Data Preparation for the Isabel Dataset\n\ndataset_name = 'isabel'\ninput_data_file = '/kaggle/input/isabel-3d/Isabel_3D.vti'\nvarname = 'Pressure'\nrun_device = 'cuda:0'\noutpath = \"/kaggle/working\"\ngroup_size = 10000\nlearning_rate = 0.00005\nMAX_EPOCH = 300\nBATCH_SIZE = 2048\nnumber_layers = 6\nneurons_per_layer = 128\nnum_input_dim = 3\nnum_neighbor = 18  # Expand number of neighbors\nnum_output_dim = 2 + num_neighbor  # mean, logvar, 18 neighbor predictions!\nweight_decay = 1e-5\nlr_schedule_stepsize = 15\nlr_gamma = 0.8\n\ndata = read_vti_file(input_data_file)\nnp_arr_coord, np_arr_vals, dims = data_setup(data, varname)\nnp_arr_vals_norm, data_min, data_max = normalize_data(np_arr_vals)\n\nprint(\"Data loaded. Pressure min:\", data_min, \"max:\", data_max)\nprint(\"Data dimensions:\", dims)\nprint(\"Total points:\", np_arr_coord.shape[0])\n\nrestored = denormalize_data(np_arr_vals_norm, data_min, data_max)\nprint(\"Restored max/min:\", np.max(restored), np.min(restored))\nassert np.allclose(np_arr_vals, restored, atol=1e-5), \"Denormalization mismatch!\"\n\ntorch_coords = torch.from_numpy(np_arr_coord)\ntorch_vals = torch.from_numpy(np_arr_vals_norm)\ntrain_dataloader = DataLoader(\n    TensorDataset(torch_coords, torch_vals),\n    batch_size=BATCH_SIZE,\n    pin_memory=True,\n    shuffle=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:29:02.768119Z","iopub.execute_input":"2025-08-05T12:29:02.768596Z","iopub.status.idle":"2025-08-05T12:29:05.908590Z","shell.execute_reply.started":"2025-08-05T12:29:02.768573Z","shell.execute_reply":"2025-08-05T12:29:05.907808Z"}},"outputs":[{"name":"stdout","text":"Data loaded. Pressure min: -4931.54248046875 max: 2594.9736328125\nData dimensions: (250, 250, 50)\nTotal points: 3125000\nRestored max/min: 2594.9736328125 -4931.54248046875\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# === Model Architecture must be DEFINED as in your Cell 3! ===\n# Ensure the class MyResidualSirenNet is defined as before prior to this cell.\n\ndevice = torch.device(run_device if torch.cuda.is_available() else \"cpu\")\nmodel = MyResidualSirenNet(\n    num_layers=number_layers,\n    neurons_per_layer=neurons_per_layer,\n    num_input_dim=num_input_dim,\n    num_output_dim=num_output_dim\n).to(device)\n\n# Path to model checkpoint (update if needed)\ncheckpoint_path = '/kaggle/input/isabel_pressure_hybrid_20output_ep227/pytorch/default/1/isabel_Pressure_hybrid_20output_ep227.pth'\n\n# Load checkpoint\ncheckpoint = torch.load(checkpoint_path, map_location=device)\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nprint(f\"Loaded model from {checkpoint_path} (epoch {checkpoint['epoch']})\")\n\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:29:05.909451Z","iopub.execute_input":"2025-08-05T12:29:05.909778Z","iopub.status.idle":"2025-08-05T12:29:05.938881Z","shell.execute_reply.started":"2025-08-05T12:29:05.909759Z","shell.execute_reply":"2025-08-05T12:29:05.938351Z"}},"outputs":[{"name":"stdout","text":"Loaded model from /kaggle/input/isabel_pressure_hybrid_20output_ep227/pytorch/default/1/isabel_Pressure_hybrid_20output_ep227.pth (epoch 227)\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"MyResidualSirenNet(\n  (net_layers): ModuleList(\n    (0): SineLayer(\n      (linear): Linear(in_features=3, out_features=128, bias=True)\n    )\n    (1-5): 5 x ResidualSineLayer(\n      (linear_1): Linear(in_features=128, out_features=128, bias=True)\n      (linear_2): Linear(in_features=128, out_features=128, bias=True)\n    )\n    (6): Linear(in_features=128, out_features=20, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"import gc\nimport matplotlib.pyplot as plt\n\nstart_time = time.time()\nprint(\"Starting inference\")\n\ndef output_chunk_generator():\n    with torch.no_grad():\n        for i in range(0, np_arr_coord.shape[0], group_size):\n            chunk = torch.from_numpy(np_arr_coord[i:i+group_size]).float().to(device)\n            out = model(chunk)\n            mean = out[:, 0:1]\n            log_var = out[:, 1:2]\n            mean_np = denormalize_data(mean.cpu().numpy(), data_min, data_max)\n            var_np = np.exp(log_var.cpu().numpy())\n            yield i, mean_np, var_np, mean.cpu().numpy(), log_var.cpu().numpy()\n            del chunk, out, mean, log_var\n            torch.cuda.empty_cache()\n            gc.collect()\n\nmean_all = np.zeros_like(np_arr_vals)\nvar_all = np.zeros_like(np_arr_vals)\nmse_denorm_total = 0.0\nmse_norm_total = 0.0\nsample_count = 0\nlog_var_all = []\n\nfor i, mean_chunk_denorm, var_chunk, mean_chunk_norm, log_var_chunk in output_chunk_generator():\n    mean_all[i:i+group_size] = mean_chunk_denorm\n    var_all[i:i+group_size] = var_chunk\n    gt_chunk = np_arr_vals[i:i+group_size]\n    gt_chunk_norm = np_arr_vals_norm[i:i+group_size]\n    mean_chunk_norm = mean_chunk_norm.reshape(-1)\n    gt_chunk_norm = gt_chunk_norm.reshape(-1)\n    mse_norm_total += np.sum((mean_chunk_norm - gt_chunk_norm) ** 2)\n    mean_chunk_denorm = mean_chunk_denorm.reshape(-1)\n    gt_chunk_denorm = gt_chunk.reshape(-1)\n    mse_denorm_total += np.sum((mean_chunk_denorm - gt_chunk_denorm) ** 2)\n    log_var_all.append(log_var_chunk)\n    sample_count += len(gt_chunk)\n\nmse_denorm = mse_denorm_total / sample_count\nmse_norm = mse_norm_total / sample_count\npsnr_denorm = 20 * np.log10((data_max - data_min) / np.sqrt(mse_denorm))\npsnr_norm = 20 * np.log10(2.0 / np.sqrt(mse_norm))\nrmse_denorm = np.sqrt(mse_denorm)\nrmse_norm = np.sqrt(mse_norm)\n\nreconstructed_min = np.min(mean_all)\nreconstructed_max = np.max(mean_all)\nlog_var_preds = np.concatenate(log_var_all, axis=0)\nvariance_vals = np.exp(log_var_preds)\nuncertainty_min = np.min(variance_vals)\nuncertainty_max = np.max(variance_vals)\n\nprint(\"METRICS:\")\nprint(f\"PSNR (Denorm): {psnr_denorm:.4f} dB\")\nprint(f\"PSNR (Norm): {psnr_norm:.4f} dB\")\nprint(f\"RMSE (Denorm): {rmse_denorm:.6f}\")\nprint(f\"RMSE (Norm): {rmse_norm:.6f}\")\nprint(\"DATA RANGES:\")\nprint(f\"Original Pressure:      [{data_min:.6f}, {data_max:.6f}]\")\nprint(f\"Reconstructed Pressure: [{reconstructed_min:.6f}, {reconstructed_max:.6f}]\")\nprint(f\"Uncertainty Range:      [{uncertainty_min:.6f}, {uncertainty_max:.6f}]\")\nprint(f\"Reconstruction Time: {time.time() - start_time:.2f} seconds\")\nprint(\"OUTPUTS:\")\n\ncombined_path = save_combined_volume(\n    data, mean_all, var_all, outpath, dataset_name,\n    postfix=f\"combined_{num_output_dim}out\"\n)\nprint(f\"Combined VTI: {combined_path}\")\nprint(f\"Model .pth used:   {checkpoint_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T12:29:05.939534Z","iopub.execute_input":"2025-08-05T12:29:05.939821Z","iopub.status.idle":"2025-08-05T12:29:37.093130Z","shell.execute_reply.started":"2025-08-05T12:29:05.939803Z","shell.execute_reply":"2025-08-05T12:29:37.092307Z"}},"outputs":[{"name":"stdout","text":"Starting inference\nMETRICS:\nPSNR (Denorm): 48.3674 dB\nPSNR (Norm): 48.3674 dB\nRMSE (Denorm): 28.722542\nRMSE (Norm): 0.007632\nDATA RANGES:\nOriginal Pressure:      [-4931.542480, 2594.973633]\nReconstructed Pressure: [-4962.839844, 2643.675293]\nUncertainty Range:      [0.000007, 0.420373]\nReconstruction Time: 22.08 seconds\nOUTPUTS:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/1604578711.py:64: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  pressure_array.SetTuple1(i, float(pressure_data[i]))\n/tmp/ipykernel_36/1604578711.py:71: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  uncertainty_array.SetTuple1(i, float(uncertainty_data[i]))\n","output_type":"stream"},{"name":"stdout","text":"Saved combined volume to: /kaggle/working/isabel_combined_20out.vti\nCombined VTI: /kaggle/working/isabel_combined_20out.vti\nModel .pth used:   /kaggle/input/isabel_pressure_hybrid_20output_ep227/pytorch/default/1/isabel_Pressure_hybrid_20output_ep227.pth\n","output_type":"stream"}],"execution_count":32}]}